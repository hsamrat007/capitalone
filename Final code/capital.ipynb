{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.10.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "‚úÖ All packages installed and imported successfully!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Install all required packages\n",
    "!pip install torch torchvision transformers\n",
    "!pip install pillow requests\n",
    "!pip install gtts pygame\n",
    "!pip install SpeechRecognition\n",
    "!pip install opencv-python\n",
    "!pip install accelerate\n",
    "!pip install pydub  # For audio file handling\"\"\"\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "import requests\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "\n",
    "# TTS and ASR imports\n",
    "from gtts import gTTS\n",
    "import pygame\n",
    "import speech_recognition as sr\n",
    "\n",
    "# Display and utility imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, Audio, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All packages installed and imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåæ Initializing Agriculture VLM...\n",
      "üöÄ Loading Vision Language Model...\n",
      "üñ•Ô∏è  Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vision Language Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "class AgricultureVLM:\n",
    "    def __init__(self, model_name=\"vikhyatk/moondream2\"):\n",
    "        \"\"\"\n",
    "        Initialize the agriculture-focused Vision Language Model\n",
    "        Using Moondream2 - a small (2B) but capable VLM perfect for cloud environments\n",
    "        \"\"\"\n",
    "        print(\"üöÄ Loading Vision Language Model...\")\n",
    "        \n",
    "        # Device setup\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"üñ•Ô∏è  Using device: {self.device}\")\n",
    "        \n",
    "        try:\n",
    "            # Load Moondream2 model\n",
    "            self.model = AutoModelForCausalLM.from_pretrained(\n",
    "                model_name,\n",
    "                trust_remote_code=True,\n",
    "                torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
    "                device_map=\"auto\" if self.device == \"cuda\" else None\n",
    "            ).to(self.device)\n",
    "            \n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "                model_name, \n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            \n",
    "            # Agriculture-specific system prompt\n",
    "            self.agriculture_context = \"\"\"\n",
    "            You are an expert agricultural assistant with deep knowledge in:\n",
    "            - Crop health and disease identification\n",
    "            - Pest detection and integrated pest management\n",
    "            - Soil conditions and nutrient management\n",
    "            - Irrigation and water management strategies\n",
    "            - Harvest timing and post-harvest techniques\n",
    "            - Weather impact assessment and mitigation\n",
    "            - Sustainable and organic farming practices\n",
    "            - Crop rotation and companion planting\n",
    "            \n",
    "            Always provide practical, actionable advice suitable for farmers.\n",
    "            Focus on cost-effective and locally appropriate solutions.\n",
    "            \"\"\"\n",
    "            \n",
    "            print(\"‚úÖ Vision Language Model loaded successfully!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading VLM: {str(e)}\")\n",
    "            raise e\n",
    "    \n",
    "    def process_query(self, image, text_query):\n",
    "        \"\"\"\n",
    "        Process image and text query for agriculture-specific insights\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Prepare the enhanced prompt\n",
    "            enhanced_prompt = f\"\"\"\n",
    "            {self.agriculture_context}\n",
    "            \n",
    "            Farmer's Question: {text_query}\n",
    "            \n",
    "            Please analyze the image and provide specific, actionable advice:\n",
    "            \"\"\"\n",
    "            \n",
    "            # Generate response using the VLM\n",
    "            response = self.model.answer_question(image, enhanced_prompt, self.tokenizer)\n",
    "            \n",
    "            return response\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing agricultural query: {str(e)}\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            return error_msg\n",
    "\n",
    "# Initialize the VLM\n",
    "print(\"üåæ Initializing Agriculture VLM...\")\n",
    "vlm_assistant = AgricultureVLM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéµ Initializing Text-to-Speech...\n",
      "‚ö†Ô∏è  Audio playback not available (cloud environment)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4732:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5220:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2642:(snd_pcm_open_noupdate) Unknown PCM default\n"
     ]
    }
   ],
   "source": [
    "class AgricultureTTS:\n",
    "    def __init__(self, language='en', output_dir='audio_responses'):\n",
    "        \"\"\"\n",
    "        Enhanced TTS for agriculture responses with file saving for cloud environments\n",
    "        \"\"\"\n",
    "        self.language = language\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # Create output directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Initialize pygame for local audio playback (optional)\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.pygame_available = True\n",
    "            print(\"üîä Audio playback available\")\n",
    "        except:\n",
    "            self.pygame_available = False\n",
    "            print(\"‚ö†Ô∏è  Audio playback not available (cloud environment)\")\n",
    "    \n",
    "    def generate_speech_file(self, text, filename=None, slow=False):\n",
    "        \"\"\"\n",
    "        Generate speech file from text - works in all environments\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if filename is None:\n",
    "                timestamp = int(time.time())\n",
    "                filename = f\"agriculture_response_{timestamp}.mp3\"\n",
    "            \n",
    "            # Ensure filename has .mp3 extension\n",
    "            if not filename.endswith('.mp3'):\n",
    "                filename += '.mp3'\n",
    "            \n",
    "            filepath = os.path.join(self.output_dir, filename)\n",
    "            \n",
    "            # Create TTS object and save\n",
    "            tts = gTTS(text=text, lang=self.language, slow=slow)\n",
    "            tts.save(filepath)\n",
    "            \n",
    "            print(f\"üíæ Speech saved: {filepath}\")\n",
    "            \n",
    "            # Try to play if possible (works locally)\n",
    "            if self.pygame_available:\n",
    "                try:\n",
    "                    pygame.mixer.music.load(filepath)\n",
    "                    pygame.mixer.music.play()\n",
    "                    \n",
    "                    # Wait for playback to finish\n",
    "                    while pygame.mixer.music.get_busy():\n",
    "                        time.sleep(0.1)\n",
    "                    \n",
    "                    print(\"üîä Audio played successfully\")\n",
    "                except:\n",
    "                    print(\"üîá Audio playback failed (normal in cloud environments)\")\n",
    "            \n",
    "            return filepath\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå TTS Error: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def speak_response(self, text, save_file=True, filename=None):\n",
    "        \"\"\"\n",
    "        Generate speech response (with optional file saving)\n",
    "        \"\"\"\n",
    "        if save_file:\n",
    "            return self.generate_speech_file(text, filename)\n",
    "        else:\n",
    "            # Quick playback without saving (if possible)\n",
    "            try:\n",
    "                tts = gTTS(text=text, lang=self.language)\n",
    "                with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as tmp_file:\n",
    "                    tts.save(tmp_file.name)\n",
    "                    \n",
    "                    if self.pygame_available:\n",
    "                        pygame.mixer.music.load(tmp_file.name)\n",
    "                        pygame.mixer.music.play()\n",
    "                        \n",
    "                        while pygame.mixer.music.get_busy():\n",
    "                            time.sleep(0.1)\n",
    "                    \n",
    "                    os.unlink(tmp_file.name)\n",
    "                    return True\n",
    "            except Exception as e:\n",
    "                print(f\"TTS Error: {e}\")\n",
    "                return False\n",
    "\n",
    "# Initialize TTS\n",
    "print(\"üéµ Initializing Text-to-Speech...\")\n",
    "tts_system = AgricultureTTS()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§ Enhanced Speech Recognition initialized\n",
      "üìÅ Supported formats: .wav, .mp3, .flac, .m4a, .aiff\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "class AgricultureASR:\n",
    "    def __init__(self, supported_formats=None):\n",
    "        \"\"\"\n",
    "        Enhanced ASR with proper MP3 support via conversion\n",
    "        \"\"\"\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        self.supported_formats = supported_formats or ['.wav', '.mp3', '.flac', '.m4a', '.aiff']\n",
    "        \n",
    "        print(\"üé§ Enhanced Speech Recognition initialized\")\n",
    "        print(f\"üìÅ Supported formats: {', '.join(self.supported_formats)}\")\n",
    "    \n",
    "    def convert_to_wav(self, audio_file_path):\n",
    "        \"\"\"\n",
    "        Convert any audio format to WAV for speech recognition\n",
    "        \"\"\"\n",
    "        try:\n",
    "            file_extension = os.path.splitext(audio_file_path)[1].lower()\n",
    "            \n",
    "            if file_extension == '.wav':\n",
    "                return audio_file_path  # Already WAV\n",
    "            \n",
    "            print(f\"üîÑ Converting {file_extension} to WAV...\")\n",
    "            \n",
    "            # Load audio file with pydub\n",
    "            if file_extension == '.mp3':\n",
    "                audio = AudioSegment.from_mp3(audio_file_path)\n",
    "            elif file_extension == '.m4a':\n",
    "                audio = AudioSegment.from_file(audio_file_path, format=\"m4a\")\n",
    "            elif file_extension == '.flac':\n",
    "                audio = AudioSegment.from_file(audio_file_path, format=\"flac\")\n",
    "            else:\n",
    "                audio = AudioSegment.from_file(audio_file_path)\n",
    "            \n",
    "            # Create temporary WAV file\n",
    "            temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "            \n",
    "            # Export as WAV with proper settings for speech recognition\n",
    "            audio.export(\n",
    "                temp_wav.name,\n",
    "                format=\"wav\",\n",
    "                parameters=[\"-ac\", \"1\", \"-ar\", \"16000\"]  # Mono, 16kHz\n",
    "            )\n",
    "            \n",
    "            print(f\"‚úÖ Converted to: {temp_wav.name}\")\n",
    "            return temp_wav.name\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Conversion error: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def validate_audio_file(self, audio_file_path):\n",
    "        \"\"\"\n",
    "        Validate audio file\n",
    "        \"\"\"\n",
    "        if not os.path.exists(audio_file_path):\n",
    "            print(f\"‚ùå Audio file not found: {audio_file_path}\")\n",
    "            return False\n",
    "        \n",
    "        file_extension = os.path.splitext(audio_file_path)[1].lower()\n",
    "        if file_extension not in self.supported_formats:\n",
    "            print(f\"‚ùå Unsupported format: {file_extension}\")\n",
    "            print(f\"Supported formats: {', '.join(self.supported_formats)}\")\n",
    "            return False\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def transcribe_audio_file(self, audio_file_path, language='en-US'):\n",
    "        \"\"\"\n",
    "        Convert audio file to text with proper MP3 support\n",
    "        \"\"\"\n",
    "        converted_file = None\n",
    "        try:\n",
    "            # Validate file first\n",
    "            if not self.validate_audio_file(audio_file_path):\n",
    "                return None\n",
    "            \n",
    "            print(f\"üéµ Processing audio file: {os.path.basename(audio_file_path)}\")\n",
    "            \n",
    "            # Convert to WAV if needed\n",
    "            wav_file = self.convert_to_wav(audio_file_path)\n",
    "            if wav_file is None:\n",
    "                return None\n",
    "            \n",
    "            converted_file = wav_file if wav_file != audio_file_path else None\n",
    "            \n",
    "            # Process with speech recognition\n",
    "            with sr.AudioFile(wav_file) as source:\n",
    "                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "                audio_data = self.recognizer.record(source)\n",
    "            \n",
    "            print(\"üîÑ Converting speech to text...\")\n",
    "            \n",
    "            # Recognize speech\n",
    "            text = self.recognizer.recognize_google(audio_data, language=language)\n",
    "            print(f\"‚úÖ Transcribed: '{text}'\")\n",
    "            \n",
    "            return text\n",
    "            \n",
    "        except sr.UnknownValueError:\n",
    "            print(\"‚ùå Could not understand the audio in the file\")\n",
    "            return None\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"‚ùå ASR service error: {e}\")\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing audio file: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            # Clean up temporary WAV file\n",
    "            if converted_file and os.path.exists(converted_file):\n",
    "                try:\n",
    "                    os.unlink(converted_file)\n",
    "                    print(\"üóëÔ∏è  Temporary file cleaned up\")\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "asr_system = AgricultureASR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Initializing Complete Agriculture Assistant...\n",
      "üåæ Agriculture Assistant initialized successfully!\n",
      "üìä Session ID: 20250808_055518\n"
     ]
    }
   ],
   "source": [
    "class AgricultureAssistant:\n",
    "    def __init__(self, vlm, tts, asr):\n",
    "        \"\"\"\n",
    "        Complete agriculture assistant with VLM, TTS, and file-based ASR\n",
    "        \"\"\"\n",
    "        self.vlm = vlm\n",
    "        self.tts = tts\n",
    "        self.asr = asr\n",
    "        self.conversation_history = []\n",
    "        self.current_image = None\n",
    "        self.session_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        print(\"üåæ Agriculture Assistant initialized successfully!\")\n",
    "        print(f\"üìä Session ID: {self.session_id}\")\n",
    "    \n",
    "    def load_image(self, image_path_or_url):\n",
    "        \"\"\"\n",
    "        Load image from file path or URL\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(f\"üì∑ Loading image: {image_path_or_url}\")\n",
    "            \n",
    "            if image_path_or_url.startswith(('http://', 'https://')):\n",
    "                response = requests.get(image_path_or_url)\n",
    "                response.raise_for_status()\n",
    "                image = Image.open(io.BytesIO(response.content))\n",
    "                print(\"‚úÖ Image loaded from URL\")\n",
    "            else:\n",
    "                image = Image.open(image_path_or_url)\n",
    "                print(\"‚úÖ Image loaded from file\")\n",
    "            \n",
    "            # Convert to RGB if necessary\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            self.current_image = image\n",
    "            \n",
    "            # Display basic image info\n",
    "            print(f\"üìê Image size: {image.size}\")\n",
    "            print(f\"üé® Image mode: {image.mode}\")\n",
    "            \n",
    "            return image\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"‚ùå Error loading image: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            return None\n",
    "    \n",
    "    def display_image(self, figsize=(10, 8)):\n",
    "        \"\"\"\n",
    "        Display the current loaded image\n",
    "        \"\"\"\n",
    "        if self.current_image is None:\n",
    "            print(\"‚ùå No image loaded. Use load_image() first.\")\n",
    "            return\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.imshow(self.current_image)\n",
    "        plt.axis('off')\n",
    "        plt.title(\"üåæ Agriculture Image for Analysis\", fontsize=14, pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def process_text_query(self, text_query, generate_voice_response=True):\n",
    "        \"\"\"\n",
    "        Process text query with current image\n",
    "        \"\"\"\n",
    "        if self.current_image is None:\n",
    "            response = \"‚ùå Please load an image first using load_image() method.\"\n",
    "            print(response)\n",
    "            return response, None\n",
    "        \n",
    "        print(f\"üåæ Processing query: '{text_query}'\")\n",
    "        print(\"üîÑ Analyzing with VLM...\")\n",
    "        \n",
    "        # Get VLM response\n",
    "        response = self.vlm.process_query(self.current_image, text_query)\n",
    "        \n",
    "        # Generate unique response filename\n",
    "        response_filename = f\"response_{self.session_id}_{len(self.conversation_history)+1}.mp3\"\n",
    "        \n",
    "        # Add to conversation history\n",
    "        conversation_entry = {\n",
    "            'type': 'text_query',\n",
    "            'query': text_query,\n",
    "            'response': response,\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'session_id': self.session_id\n",
    "        }\n",
    "        \n",
    "        # Generate voice response if requested\n",
    "        audio_file = None\n",
    "        if generate_voice_response:\n",
    "            print(\"üîä Generating voice response...\")\n",
    "            audio_file = self.tts.generate_speech_file(response, response_filename)\n",
    "            conversation_entry['response_audio'] = audio_file\n",
    "        \n",
    "        self.conversation_history.append(conversation_entry)\n",
    "        \n",
    "        print(f\"\\nüìù Response: {response}\\n\")\n",
    "        if audio_file:\n",
    "            print(f\"üéµ Voice response saved: {audio_file}\")\n",
    "        \n",
    "        return response, audio_file\n",
    "    \n",
    "    def process_voice_query(self, audio_file_path, generate_voice_response=True, language='en-US'):\n",
    "        \"\"\"\n",
    "        Process voice query from audio file\n",
    "        \"\"\"\n",
    "        if self.current_image is None:\n",
    "            response = \"‚ùå Please load an image first using load_image() method.\"\n",
    "            print(response)\n",
    "            if generate_voice_response:\n",
    "                audio_file = self.tts.generate_speech_file(response, \"error_no_image.mp3\")\n",
    "                return response, None, audio_file\n",
    "            return response, None, None\n",
    "        \n",
    "        print(f\"üé§ Processing voice query from: {os.path.basename(audio_file_path)}\")\n",
    "        \n",
    "        # Get audio file info\n",
    "        self.asr.get_audio_info(audio_file_path)\n",
    "        \n",
    "        # Transcribe audio to text\n",
    "        text_query = self.asr.transcribe_audio_file(audio_file_path, language)\n",
    "        \n",
    "        if text_query is None:\n",
    "            response = \"‚ùå Could not understand the audio. Please ensure clear speech and supported audio format.\"\n",
    "            print(response)\n",
    "            if generate_voice_response:\n",
    "                audio_file = self.tts.generate_speech_file(response, \"error_transcription.mp3\")\n",
    "                return response, None, audio_file\n",
    "            return response, None, None\n",
    "        \n",
    "        print(f\"üåæ Transcribed query: '{text_query}'\")\n",
    "        print(\"üîÑ Analyzing with VLM...\")\n",
    "        \n",
    "        # Get VLM response\n",
    "        vlm_response = self.vlm.process_query(self.current_image, text_query)\n",
    "        \n",
    "        # Generate unique response filename\n",
    "        response_filename = f\"voice_response_{self.session_id}_{len(self.conversation_history)+1}.mp3\"\n",
    "        \n",
    "        # Add to conversation history\n",
    "        conversation_entry = {\n",
    "            'type': 'voice_query',\n",
    "            'audio_file': audio_file_path,\n",
    "            'transcribed_query': text_query,\n",
    "            'response': vlm_response,\n",
    "            'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            'session_id': self.session_id\n",
    "        }\n",
    "        \n",
    "        # Generate voice response if requested\n",
    "        response_audio_file = None\n",
    "        if generate_voice_response:\n",
    "            print(\"üîä Generating voice response...\")\n",
    "            response_audio_file = self.tts.generate_speech_file(vlm_response, response_filename)\n",
    "            conversation_entry['response_audio'] = response_audio_file\n",
    "        \n",
    "        self.conversation_history.append(conversation_entry)\n",
    "        \n",
    "        print(f\"\\nüìù Response: {vlm_response}\\n\")\n",
    "        if response_audio_file:\n",
    "            print(f\"üéµ Voice response saved: {response_audio_file}\")\n",
    "        \n",
    "        return vlm_response, text_query, response_audio_file\n",
    "    \n",
    "    def batch_voice_analysis(self, image_path, audio_files_list, language='en-US'):\n",
    "        \"\"\"\n",
    "        Analyze multiple voice queries for the same image\n",
    "        \"\"\"\n",
    "        # Load the image\n",
    "        if not self.load_image(image_path):\n",
    "            return None\n",
    "        \n",
    "        self.display_image()\n",
    "        \n",
    "        print(f\"üîÑ Starting batch analysis of {len(audio_files_list)} voice queries...\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        batch_results = []\n",
    "        \n",
    "        for i, audio_file in enumerate(audio_files_list, 1):\n",
    "            print(f\"\\nüé§ Processing query {i}/{len(audio_files_list)}: {os.path.basename(audio_file)}\")\n",
    "            print(\"-\" * 60)\n",
    "            \n",
    "            response, query, response_audio = self.process_voice_query(\n",
    "                audio_file, \n",
    "                generate_voice_response=True,\n",
    "                language=language\n",
    "            )\n",
    "            \n",
    "            result = {\n",
    "                'query_number': i,\n",
    "                'audio_file': audio_file,\n",
    "                'transcribed_query': query,\n",
    "                'vlm_response': response,\n",
    "                'response_audio_file': response_audio,\n",
    "                'processing_time': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            }\n",
    "            \n",
    "            batch_results.append(result)\n",
    "            \n",
    "            print(f\"‚úÖ Query {i} completed\")\n",
    "            time.sleep(2)  # Brief pause between queries\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        print(f\"üéâ Batch analysis completed! Processed {len(batch_results)} queries.\")\n",
    "        \n",
    "        return batch_results\n",
    "    \n",
    "    def show_conversation_history(self, save_to_file=False):\n",
    "        \"\"\"\n",
    "        Display and optionally save conversation history\n",
    "        \"\"\"\n",
    "        if not self.conversation_history:\n",
    "            print(\"üì≠ No conversation history yet.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nüìö Conversation History (Session: {self.session_id})\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        history_text = []\n",
    "        \n",
    "        for i, entry in enumerate(self.conversation_history, 1):\n",
    "            print(f\"\\n{i}. [{entry['timestamp']}] - {entry['type'].title()}\")\n",
    "            \n",
    "            if entry['type'] == 'voice_query':\n",
    "                print(f\"   üé§ Audio File: {os.path.basename(entry['audio_file'])}\")\n",
    "                print(f\"   üìù Transcribed: {entry['transcribed_query']}\")\n",
    "                if 'response_audio' in entry:\n",
    "                    print(f\"   üîä Response Audio: {os.path.basename(entry['response_audio'])}\")\n",
    "            else:\n",
    "                print(f\"   üìù Query: {entry['query']}\")\n",
    "            \n",
    "            print(f\"   ü§ñ Response: {entry['response'][:100]}...\")\n",
    "            \n",
    "            # Add to history text for saving\n",
    "            history_text.append(f\"{i}. [{entry['timestamp']}] - {entry['type'].title()}\")\n",
    "            if entry['type'] == 'voice_query':\n",
    "                history_text.append(f\"   Audio: {entry['audio_file']}\")\n",
    "                history_text.append(f\"   Query: {entry['transcribed_query']}\")\n",
    "            else:\n",
    "                history_text.append(f\"   Query: {entry['query']}\")\n",
    "            history_text.append(f\"   Response: {entry['response']}\")\n",
    "            history_text.append(\"\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Save to file if requested\n",
    "        if save_to_file:\n",
    "            history_filename = f\"conversation_history_{self.session_id}.txt\"\n",
    "            with open(history_filename, 'w', encoding='utf-8') as f:\n",
    "                f.write(f\"Agriculture Assistant Conversation History\\n\")\n",
    "                f.write(f\"Session ID: {self.session_id}\\n\")\n",
    "                f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "                f.write(\"\\n\".join(history_text))\n",
    "            \n",
    "            print(f\"üíæ History saved to: {history_filename}\")\n",
    "    \n",
    "    def get_session_summary(self):\n",
    "        \"\"\"\n",
    "        Get summary of current session\n",
    "        \"\"\"\n",
    "        total_queries = len(self.conversation_history)\n",
    "        voice_queries = len([h for h in self.conversation_history if h['type'] == 'voice_query'])\n",
    "        text_queries = total_queries - voice_queries\n",
    "        \n",
    "        summary = {\n",
    "            'session_id': self.session_id,\n",
    "            'total_queries': total_queries,\n",
    "            'voice_queries': voice_queries,\n",
    "            'text_queries': text_queries,\n",
    "            'has_image_loaded': self.current_image is not None,\n",
    "            'session_start': self.conversation_history[0]['timestamp'] if self.conversation_history else None,\n",
    "            'last_activity': self.conversation_history[-1]['timestamp'] if self.conversation_history else None\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "\n",
    "# Initialize the complete agriculture assistant\n",
    "print(\"üöÄ Initializing Complete Agriculture Assistant...\")\n",
    "agriculture_assistant = AgricultureAssistant(vlm_assistant, tts_system, asr_system)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Agriculture VLM Assistant Ready!\n",
      "\n",
      "üöÄ Available Demo Functions:\n",
      "1. demo_single_voice_query()\n",
      "2. demo_batch_analysis()\n",
      "3. demo_quick_analysis('disease_detection')\n",
      "4. create_recording_guide()\n",
      "\n",
      "üéØ Available Analysis Types:\n",
      "  ‚Ä¢ disease_detection: Analyze this crop image for any plant diseases. Wh...\n",
      "  ‚Ä¢ pest_identification: Identify any pests or insects visible in this imag...\n",
      "  ‚Ä¢ nutrient_deficiency: Examine the plant leaves and overall appearance. D...\n",
      "  ‚Ä¢ growth_stage: What growth stage is this crop in? What specific c...\n",
      "  ‚Ä¢ harvest_readiness: Is this crop ready for harvest? What indicators sh...\n",
      "  ‚Ä¢ soil_health: Assess the soil condition visible in this image. W...\n",
      "  ‚Ä¢ irrigation_needs: Based on the plant and soil condition, what are th...\n",
      "  ‚Ä¢ weather_damage: Do you see any weather-related damage to these cro...\n",
      "\n",
      "üìä Session Info:\n",
      "  session_id: 20250806_051248\n",
      "  total_queries: 0\n",
      "  voice_queries: 0\n",
      "  text_queries: 0\n",
      "  has_image_loaded: False\n",
      "  session_start: None\n",
      "  last_activity: None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "AGRICULTURE_QUERIES = {\n",
    "    \"disease_detection\": \"Analyze this crop image for any plant diseases. What symptoms do you see and what treatment do you recommend?\",\n",
    "    \"pest_identification\": \"Identify any pests or insects visible in this image. What damage are they causing and how should I control them?\",\n",
    "    \"nutrient_deficiency\": \"Examine the plant leaves and overall appearance. Do you see signs of nutrient deficiency? What fertilizers should I apply?\",\n",
    "    \"growth_stage\": \"What growth stage is this crop in? What specific care and management does it need at this stage?\",\n",
    "    \"harvest_readiness\": \"Is this crop ready for harvest? What indicators should I look for to determine optimal harvest timing?\",\n",
    "    \"soil_health\": \"Assess the soil condition visible in this image. What improvements can I make for better crop production?\",\n",
    "    \"irrigation_needs\": \"Based on the plant and soil condition, what are the current irrigation requirements?\",\n",
    "    \"weather_damage\": \"Do you see any weather-related damage to these crops? How can I protect them better in the future?\"\n",
    "}\n",
    "\n",
    "def demo_single_voice_query():\n",
    "    \"\"\"\n",
    "    Demo: Single voice query analysis\n",
    "    \"\"\"\n",
    "    print(\"üé§ Demo: Single Voice Query Analysis\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Example usage (replace with your actual files)\n",
    "    image_path = \"crop_image.jpg\"  # Replace with your crop image\n",
    "    audio_file = \"farmer_question.wav\"  # Replace with your audio file\n",
    "    \n",
    "    print(\"üìã Steps to use:\")\n",
    "    print(\"1. Replace 'crop_image.jpg' with your actual crop image path\")\n",
    "    print(\"2. Replace 'farmer_question.wav' with your actual audio file path\")\n",
    "    print(\"3. Run the analysis\")\n",
    "    \n",
    "    # Example code structure:\n",
    "    example_code = '''\n",
    "    # Load crop image\n",
    "    agriculture_assistant.load_image(\"your_crop_image.jpg\")\n",
    "    agriculture_assistant.display_image()\n",
    "    \n",
    "    # Process voice query\n",
    "    response, query, audio_response = agriculture_assistant.process_voice_query(\n",
    "        \"your_audio_question.wav\",\n",
    "        generate_voice_response=True\n",
    "    )\n",
    "    '''\n",
    "    print(f\"üíª Example code:\\n{example_code}\")\n",
    "\n",
    "def demo_batch_analysis():\n",
    "    \"\"\"\n",
    "    Demo: Batch voice query analysis\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Demo: Batch Voice Analysis\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    example_code = '''\n",
    "    # Multiple audio files for the same crop\n",
    "    audio_files = [\n",
    "        \"question1.wav\",  # \"What disease is affecting my tomatoes?\"\n",
    "        \"question2.wav\",  # \"How should I treat this plant?\"\n",
    "        \"question3.wav\"   # \"When should I apply fertilizer?\"\n",
    "    ]\n",
    "    \n",
    "    # Run batch analysis\n",
    "    results = agriculture_assistant.batch_voice_analysis(\n",
    "        image_path=\"tomato_crop.jpg\",\n",
    "        audio_files_list=audio_files\n",
    "    )\n",
    "    '''\n",
    "    print(f\"üíª Example code:\\n{example_code}\")\n",
    "\n",
    "def demo_quick_analysis(query_type=\"disease_detection\"):\n",
    "    \"\"\"\n",
    "    Demo: Quick analysis with predefined queries\n",
    "    \"\"\"\n",
    "    if query_type in AGRICULTURE_QUERIES:\n",
    "        query = AGRICULTURE_QUERIES[query_type]\n",
    "        print(f\"üéØ Quick Analysis: {query_type.replace('_', ' ').title()}\")\n",
    "        print(f\"üìù Query: {query}\")\n",
    "        \n",
    "        example_code = f'''\n",
    "        # Load image\n",
    "        agriculture_assistant.load_image(\"your_crop_image.jpg\")\n",
    "        \n",
    "        # Run quick analysis\n",
    "        response, audio_file = agriculture_assistant.process_text_query(\n",
    "            \"{query}\",\n",
    "            generate_voice_response=True\n",
    "        )\n",
    "        '''\n",
    "        print(f\"üíª Code:\\n{example_code}\")\n",
    "    else:\n",
    "        print(f\"Available analysis types: {list(AGRICULTURE_QUERIES.keys())}\")\n",
    "\n",
    "def create_recording_guide():\n",
    "    \"\"\"\n",
    "    Guide for recording audio queries\n",
    "    \"\"\"\n",
    "    print(\"üéôÔ∏è Audio Recording Guide for Farmers\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    recording_tips = [\n",
    "        \"üîá Record in a quiet environment\",\n",
    "        \"üó£Ô∏è  Speak clearly and at normal speed\", \n",
    "        \"‚è±Ô∏è  Keep recordings between 5-30 seconds\",\n",
    "        \"üì± Use your phone's voice recorder app\",\n",
    "        \"üíæ Save as WAV, MP3, or FLAC format\",\n",
    "        \"üåê Ensure internet connection for transcription\"\n",
    "    ]\n",
    "    \n",
    "    sample_queries = [\n",
    "        \"What disease is affecting my crops?\",\n",
    "        \"How should I treat these brown spots on leaves?\",\n",
    "        \"Is this crop ready for harvest?\",\n",
    "        \"What fertilizer should I apply now?\",\n",
    "        \"How can I control these pests?\",\n",
    "        \"What is causing the yellowing of leaves?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üìã Recording Tips:\")\n",
    "    for tip in recording_tips:\n",
    "        print(f\"  {tip}\")\n",
    "    \n",
    "    print(\"\\nüé§ Sample Questions to Record:\")\n",
    "    for i, query in enumerate(sample_queries, 1):\n",
    "        print(f\"  {i}. \\\"{query}\\\"\")\n",
    "    \n",
    "    print(\"\\nüìÅ Supported Audio Formats:\")\n",
    "    for fmt in ['.wav', '.mp3', '.flac', '.m4a']:\n",
    "        print(f\"  ‚úÖ {fmt}\")\n",
    "\n",
    "# Run demos\n",
    "print(\"üéâ Agriculture VLM Assistant Ready!\")\n",
    "print(\"\\nüöÄ Available Demo Functions:\")\n",
    "print(\"1. demo_single_voice_query()\")\n",
    "print(\"2. demo_batch_analysis()\")  \n",
    "print(\"3. demo_quick_analysis('disease_detection')\")\n",
    "print(\"4. create_recording_guide()\")\n",
    "\n",
    "print(f\"\\nüéØ Available Analysis Types:\")\n",
    "for key, desc in AGRICULTURE_QUERIES.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {desc[:50]}...\")\n",
    "\n",
    "print(f\"\\nüìä Session Info:\")\n",
    "summary = agriculture_assistant.get_session_summary()\n",
    "for key, value in summary.items():\n",
    "    print(f\"  {key}: {value}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
